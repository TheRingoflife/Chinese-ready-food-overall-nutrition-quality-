import streamlit as st
import numpy as np
import pandas as pd
import joblib
import matplotlib.pyplot as plt
import streamlit.components.v1 as components
import warnings

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings('ignore')

# ===== å¤šè¯­è¨€é…ç½® =====
LANGUAGES = {
    "English": "en",
    "ä¸­æ–‡": "zh"
}

TEXTS = {
    "en": {
        "title": "ğŸ± Nutritional Quality Classifier",
        "subtitle": "Smart Food Health Assessment for Information-Poor Regions",
        "description": "This AI-powered app helps consumers in regions with limited nutritional information understand the healthiness of ready-to-eat foods using just 4 simple inputs.",
        "target_countries": "**Target Regions:** Developing countries and regions with limited nutritional labeling (Southeast Asia, Africa, Latin America, parts of Eastern Europe)",
        "problem_statement": "**The Challenge:** Many countries lack comprehensive nutritional labeling, making it difficult for consumers to make informed food choices.",
        "solution": "**Our Solution:** Use AI to predict food healthiness from basic nutritional data that's commonly available.",
        "input_vars": "Input Variables",
        "sodium": "Sodium (mg/100g)",
        "protein": "Protein (g/100g)",
        "processed": "Is Ultra-Processed? (procef_4)",
        "energy": "Energy (kJ/100g)",
        "predict": "ğŸ§® Assess Healthiness",
        "prediction_result": "Health Assessment Result",
        "healthy": "âœ… Healthy",
        "unhealthy": "âš ï¸ Unhealthy",
        "confidence": "Confidence (probability of being healthy)",
        "model_explanation": "AI Explanation (SHAP)",
        "feature_importance": "Feature Importance",
        "waterfall_plot": "Waterfall Plot",
        "force_plot": "AI Decision Explanation",
        "force_plot_expand": "Click to view detailed AI explanation",
        "feature_impact": "Feature Impact Analysis",
        "impact_explanation": "How each factor affects healthiness:",
        "recommendations": "Health Improvement Suggestions",
        "unhealthy_advice": "This food item is classified as unhealthy. Consider:",
        "healthy_advice": "This food item is classified as healthy! âœ…",
        "reduce_sodium": "Reduce sodium content",
        "lower_energy": "Lower energy density",
        "increase_protein": "Increase protein content",
        "less_processed": "Consider less processed alternatives",
        "keep_healthy": "Keep up the good nutritional choices!",
        "about_title": "About This App",
        "mission": "Our Mission",
        "mission_text": "Empowering consumers in nutrition-information-poor regions to make informed food choices through AI technology.",
        "model_info": "AI Model Information",
        "algorithm": "Algorithm",
        "features": "Features",
        "training": "Training",
        "accuracy": "Accuracy",
        "features_used": "Required Inputs",
        "sodium_content": "Sodium content",
        "protein_content": "Protein content",
        "processing_level": "Processing level",
        "energy_content": "Energy content",
        "classification": "Health Classification",
        "healthy_label": "Healthy",
        "unhealthy_label": "Unhealthy",
        "based_on": "Based on nutritional features",
        "use_cases": "Use Cases",
        "use_case_1": "â€¢ Consumers in developing countries",
        "use_case_2": "â€¢ Food manufacturers without detailed labeling",
        "use_case_3": "â€¢ Health organizations in resource-limited areas",
        "use_case_4": "â€¢ Import/export food quality assessment",
        "footer": "Developed using Streamlit and XGBoost Â· For global health equity",
        "copyright": "Â© 2024 Nutritional Quality Classifier"
    },
    "zh": {
        "title": "ğŸ± è¥å…»è´¨é‡åˆ†ç±»å™¨",
        "subtitle": "ä¿¡æ¯ç¼ºå¤±åœ°åŒºçš„æ™ºèƒ½é£Ÿå“å¥åº·è¯„ä¼°",
        "description": "è¿™ä¸ªAIé©±åŠ¨çš„åº”ç”¨ç¨‹åºå¸®åŠ©è¥å…»ç´ ä¿¡æ¯ç¼ºå¤±åœ°åŒºçš„æ¶ˆè´¹è€…ä»…ä½¿ç”¨4ä¸ªç®€å•è¾“å…¥å°±èƒ½äº†è§£å³é£Ÿé£Ÿå“çš„å¥åº·ç¨‹åº¦ã€‚",
        "target_countries": "**ç›®æ ‡åœ°åŒºï¼š** è¥å…»ç´ ä¿¡æ¯ç¼ºå¤±çš„å‘å±•ä¸­å›½å®¶å’Œåœ°åŒºï¼ˆä¸œå—äºšã€éæ´²ã€æ‹‰ä¸ç¾æ´²ã€ä¸œæ¬§éƒ¨åˆ†åœ°åŒºï¼‰",
        "problem_statement": "**é¢ä¸´çš„æŒ‘æˆ˜ï¼š** è®¸å¤šå›½å®¶ç¼ºä¹å…¨é¢çš„è¥å…»æ ‡ç­¾ï¼Œæ¶ˆè´¹è€…éš¾ä»¥åšå‡ºæ˜æ™ºçš„é£Ÿå“é€‰æ‹©ã€‚",
        "solution": "**æˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆï¼š** ä½¿ç”¨AIä»å¸¸è§çš„åŸºæœ¬è¥å…»æ•°æ®é¢„æµ‹é£Ÿå“å¥åº·ç¨‹åº¦ã€‚",
        "input_vars": "è¾“å…¥å˜é‡",
        "sodium": "é’ å«é‡ (æ¯«å…‹/100å…‹)",
        "protein": "è›‹ç™½è´¨å«é‡ (å…‹/100å…‹)",
        "processed": "æ˜¯å¦è¶…åŠ å·¥? (procef_4)",
        "energy": "èƒ½é‡ (åƒç„¦/100å…‹)",
        "predict": "ğŸ§® è¯„ä¼°å¥åº·ç¨‹åº¦",
        "prediction_result": "å¥åº·è¯„ä¼°ç»“æœ",
        "healthy": "âœ… å¥åº·",
        "unhealthy": "âš ï¸ ä¸å¥åº·",
        "confidence": "ç½®ä¿¡åº¦ (å¥åº·çš„å¯èƒ½æ€§)",
        "model_explanation": "AIè§£é‡Š (SHAP)",
        "feature_importance": "ç‰¹å¾é‡è¦æ€§",
        "waterfall_plot": "ç€‘å¸ƒå›¾",
        "force_plot": "AIå†³ç­–è§£é‡Š",
        "force_plot_expand": "ç‚¹å‡»æŸ¥çœ‹è¯¦ç»†AIè§£é‡Š",
        "feature_impact": "ç‰¹å¾å½±å“åˆ†æ",
        "impact_explanation": "æ¯ä¸ªå› ç´ å¦‚ä½•å½±å“å¥åº·ç¨‹åº¦ï¼š",
        "recommendations": "å¥åº·æ”¹å–„å»ºè®®",
        "unhealthy_advice": "è¯¥é£Ÿå“è¢«åˆ†ç±»ä¸ºä¸å¥åº·ã€‚å»ºè®®ï¼š",
        "healthy_advice": "è¯¥é£Ÿå“è¢«åˆ†ç±»ä¸ºå¥åº·ï¼âœ…",
        "reduce_sodium": "å‡å°‘é’ å«é‡",
        "lower_energy": "é™ä½èƒ½é‡å¯†åº¦",
        "increase_protein": "å¢åŠ è›‹ç™½è´¨å«é‡",
        "less_processed": "è€ƒè™‘è¾ƒå°‘åŠ å·¥çš„æ›¿ä»£å“",
        "keep_healthy": "ç»§ç»­ä¿æŒè‰¯å¥½çš„è¥å…»é€‰æ‹©ï¼",
        "about_title": "å…³äºæ­¤åº”ç”¨",
        "mission": "æˆ‘ä»¬çš„ä½¿å‘½",
        "mission_text": "é€šè¿‡AIæŠ€æœ¯èµ‹èƒ½è¥å…»ç´ ä¿¡æ¯ç¼ºå¤±åœ°åŒºçš„æ¶ˆè´¹è€…åšå‡ºæ˜æ™ºçš„é£Ÿå“é€‰æ‹©ã€‚",
        "model_info": "AIæ¨¡å‹ä¿¡æ¯",
        "algorithm": "ç®—æ³•",
        "features": "ç‰¹å¾",
        "training": "è®­ç»ƒ",
        "accuracy": "å‡†ç¡®ç‡",
        "features_used": "æ‰€éœ€è¾“å…¥",
        "sodium_content": "é’ å«é‡",
        "protein_content": "è›‹ç™½è´¨å«é‡",
        "processing_level": "åŠ å·¥æ°´å¹³",
        "energy_content": "èƒ½é‡å«é‡",
        "classification": "å¥åº·åˆ†ç±»",
        "healthy_label": "å¥åº·",
        "unhealthy_label": "ä¸å¥åº·",
        "based_on": "åŸºäºè¥å…»ç‰¹å¾",
        "use_cases": "åº”ç”¨åœºæ™¯",
        "use_case_1": "â€¢ å‘å±•ä¸­å›½å®¶çš„æ¶ˆè´¹è€…",
        "use_case_2": "â€¢ ç¼ºä¹è¯¦ç»†æ ‡ç­¾çš„é£Ÿå“åˆ¶é€ å•†",
        "use_case_3": "â€¢ èµ„æºæœ‰é™åœ°åŒºçš„å¥åº·ç»„ç»‡",
        "use_case_4": "â€¢ è¿›å‡ºå£é£Ÿå“è´¨é‡è¯„ä¼°",
        "footer": "ä½¿ç”¨Streamlitå’ŒXGBoostå¼€å‘ Â· ä¿ƒè¿›å…¨çƒå¥åº·å…¬å¹³",
        "copyright": "Â© 2024 è¥å…»è´¨é‡åˆ†ç±»å™¨"
    }
}

# ===== é¡µé¢è®¾ç½® =====
st.set_page_config(
    page_title="Nutritional Quality Classifier", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# ===== è¯­è¨€é€‰æ‹© =====
col1, col2 = st.columns([1, 4])
with col1:
    selected_lang = st.selectbox("Language / è¯­è¨€", list(LANGUAGES.keys()))
with col2:
    st.markdown("")

lang_code = LANGUAGES[selected_lang]
texts = TEXTS[lang_code]

# ===== è‡ªå®šä¹‰CSSæ ·å¼ =====
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #2E8B57;
        text-align: center;
        margin-bottom: 1rem;
    }
    .prediction-healthy {
        background-color: #d4edda;
        color: #155724;
        padding: 1rem;
        border-radius: 0.5rem;
        border: 1px solid #c3e6cb;
    }
    .prediction-unhealthy {
        background-color: #f8d7da;
        color: #721c24;
        padding: 1rem;
        border-radius: 0.5rem;
        border: 1px solid #f5c6cb;
    }
    .target-countries {
        background-color: #e7f3ff;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 5px solid #2E8B57;
        margin: 1rem 0;
    }
    .problem-solution {
        background-color: #fff3cd;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 5px solid #ffc107;
        margin: 1rem 0;
    }
    .mission-box {
        background-color: #d1ecf1;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 5px solid #17a2b8;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# ===== æ ‡é¢˜å’Œæè¿° =====
st.markdown(f'<h1 class="main-header">{texts["title"]}</h1>', unsafe_allow_html=True)
st.markdown(f"""
<div style="text-align: center; margin-bottom: 1rem;">
    <p style="font-size: 1.2rem; color: #666;">
        {texts["subtitle"]}
    </p>
</div>
""", unsafe_allow_html=True)

st.markdown(f"""
<div class="target-countries">
    <p style="margin: 0; font-size: 1rem;">
        {texts["description"]}
    </p>
    <br>
    <p style="margin: 0; font-size: 0.9rem; color: #666;">
        {texts["target_countries"]}
    </p>
</div>
""", unsafe_allow_html=True)

st.markdown(f"""
<div class="problem-solution">
    <p style="margin: 0; font-size: 1rem; font-weight: bold;">
        {texts["problem_statement"]}
    </p>
    <br>
    <p style="margin: 0; font-size: 1rem;">
        {texts["solution"]}
    </p>
</div>
""", unsafe_allow_html=True)

# ===== åŠ è½½æ¨¡å‹ã€æ ‡å‡†åŒ–å™¨å’ŒèƒŒæ™¯æ•°æ® =====
@st.cache_resource
def load_model():
    try:
        model = joblib.load("XGBoost_retrained_model.pkl")
        st.success("âœ… AI Model loaded successfully" if lang_code == "en" else "âœ… AIæ¨¡å‹åŠ è½½æˆåŠŸ")
        return model
    except Exception as e:
        st.error(f"âŒ Failed to load model: {e}" if lang_code == "en" else f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None

@st.cache_resource
def load_scaler():
    try:
        scaler = joblib.load("scaler2.pkl")
        st.success("âœ… Data processor loaded successfully" if lang_code == "en" else "âœ… æ•°æ®å¤„ç†å™¨åŠ è½½æˆåŠŸ")
        return scaler
    except Exception as e:
        st.error(f"âŒ Failed to load scaler: {e}" if lang_code == "en" else f"âŒ æ•°æ®å¤„ç†å™¨åŠ è½½å¤±è´¥: {e}")
        return None

@st.cache_resource
def load_background_data():
    try:
        data = np.load("background_data.npy")
        st.success("âœ… Reference data loaded successfully" if lang_code == "en" else "âœ… å‚è€ƒæ•°æ®åŠ è½½æˆåŠŸ")
        return data
    except Exception as e:
        st.warning(f"âš ï¸ Failed to load background data: {e}" if lang_code == "en" else f"âš ï¸ å‚è€ƒæ•°æ®åŠ è½½å¤±è´¥: {e}")
        st.warning("Creating simulated reference data..." if lang_code == "en" else "åˆ›å»ºæ¨¡æ‹Ÿå‚è€ƒæ•°æ®...")
        np.random.seed(42)
        return np.random.normal(0, 1, (100, 4))

@st.cache_resource
def create_explainer(model, background_data):
    try:
        import shap
        explainer = shap.Explainer(model, background_data)
        st.success("âœ… AI explanation engine ready" if lang_code == "en" else "âœ… AIè§£é‡Šå¼•æ“å°±ç»ª")
        return explainer
    except Exception as e:
        st.warning(f"âš ï¸ Failed to create explanation engine: {e}" if lang_code == "en" else f"âš ï¸ è§£é‡Šå¼•æ“åˆ›å»ºå¤±è´¥: {e}")
        return None

# åŠ è½½ç»„ä»¶
with st.spinner("ğŸ”„ Loading AI system..." if lang_code == "en" else "ğŸ”„ åŠ è½½AIç³»ç»Ÿ..."):
    model = load_model()
    scaler = load_scaler()
    background_data = load_background_data()
    explainer = create_explainer(model, background_data)

if model is None or scaler is None:
    st.error("âŒ Cannot proceed without AI model" if lang_code == "en" else "âŒ æ— æ³•åœ¨æ²¡æœ‰AIæ¨¡å‹çš„æƒ…å†µä¸‹ç»§ç»­")
    st.stop()

# æ˜¾ç¤ºåŠ è½½çŠ¶æ€
st.info(f"ğŸ¤– AI Model: {type(model).__name__}" if lang_code == "en" else f"ğŸ¤– AIæ¨¡å‹: {type(model).__name__}")
st.info(f"ğŸ“Š Required inputs: {len(scaler.feature_names_in_) if hasattr(scaler, 'feature_names_in_') else 'Unknown'}" if lang_code == "en" else f"ğŸ“Š æ‰€éœ€è¾“å…¥: {len(scaler.feature_names_in_) if hasattr(scaler, 'feature_names_in_') else 'æœªçŸ¥'}")
st.info(f"ğŸ“Š Reference data: {background_data.shape}" if lang_code == "en" else f"ğŸ“Š å‚è€ƒæ•°æ®: {background_data.shape}")

# ===== ä¾§è¾¹æ è¾“å…¥ =====
st.sidebar.header(f"ğŸ”¢ {texts['input_vars']}")
st.sidebar.markdown("*Enter basic nutritional information commonly available on food labels*" if lang_code == "en" else "*è¾“å…¥é£Ÿå“æ ‡ç­¾ä¸Šå¸¸è§çš„åŸºæœ¬è¥å…»ä¿¡æ¯*")

sodium = st.sidebar.number_input(texts["sodium"], min_value=0.0, step=1.0, value=400.0)
protein = st.sidebar.number_input(texts["protein"], min_value=0.0, step=0.1, value=15.0)
procef_4 = st.sidebar.selectbox(texts["processed"], [0, 1])
energy = st.sidebar.number_input(texts["energy"], min_value=0.0, step=1.0, value=1000.0)

# ===== æ¨¡å‹é¢„æµ‹ + SHAP å¯è§£é‡Šæ€§ =====
if st.sidebar.button(texts["predict"], type="primary", use_container_width=True):
    try:
        # 1. å‡†å¤‡è¾“å…¥æ•°æ®ï¼ˆ4ä¸ªç‰¹å¾ï¼‰
        input_data = np.array([[sodium, protein, procef_4, energy]])
        
        # 2. æ ‡å‡†åŒ–
        input_scaled = scaler.transform(input_data)
        
        # 3. åˆ›å»ºDataFrame
        user_scaled_df = pd.DataFrame(input_scaled, columns=['Sodium', 'Protein', 'procef_4', 'Energy'])
        
        # 4. é¢„æµ‹
        prediction = model.predict(user_scaled_df)[0]
        prob = model.predict_proba(user_scaled_df)[0][1]
        
        # 5. å±•ç¤ºç»“æœ
        st.subheader(f"ğŸ” {texts['prediction_result']}")
        label = texts["healthy"] if prediction == 1 else texts["unhealthy"]
        st.markdown(f"**{texts['prediction_result'].split(':')[0] if ':' in texts['prediction_result'] else 'Assessment'}:** {label}")
        st.markdown(f"**{texts['confidence']}:** `{prob:.2f}`")
        
        # 6. SHAPè§£é‡Š
        if explainer is not None:
            st.subheader(f"ğŸ“Š {texts['model_explanation']}")
            
            try:
                # è®¡ç®—SHAPå€¼
                shap_values = explainer(user_scaled_df)
                
                # åˆ›å»ºSHAPå¯è§†åŒ–
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown(f"#### {texts['feature_importance']}")
                    import shap
                    shap.plots.bar(shap_values, show=False)
                    st.pyplot(plt.gcf())
                    plt.close()
                
                with col2:
                    st.markdown(f"#### {texts['waterfall_plot']}")
                    shap.waterfall_plot(shap_values[0], show=False)
                    st.pyplot(plt.gcf())
                    plt.close()
                
                # SHAP Force Plot (åŠ›å›¾)
                st.subheader(f"ğŸ“Š {texts['force_plot']}")
                with st.expander(texts["force_plot_expand"]):
                    if isinstance(shap_values, list):
                        shap_values_force = shap_values[1]
                    else:
                        shap_values_force = shap_values
                    
                    if not isinstance(shap_values_force, shap.Explanation):
                        shap_values_force = shap.Explanation(
                            values=shap_values_force,
                            base_values=explainer.expected_value[1] if isinstance(explainer.expected_value, list) else explainer.expected_value,
                            data=user_scaled_df.values,
                            feature_names=user_scaled_df.columns.tolist()
                        )
                    
                    force_html = shap.force_plot(
                        base_value=shap_values_force.base_values,
                        shap_values=shap_values_force.values,
                        features=shap_values_force.data,
                        feature_names=shap_values_force.feature_names,
                        matplotlib=False
                    )
                    components.html(shap.getjs() + force_html.html(), height=400)
                
                # ç‰¹å¾å½±å“åˆ†æè¡¨æ ¼
                st.markdown(f"#### {texts['feature_impact']}")
                feature_impact = pd.DataFrame({
                    'Feature': ['Sodium', 'Protein', 'procef_4', 'Energy'],
                    'Input Value': input_data[0],
                    'SHAP Value': shap_values.values[0],
                    'Impact': ['Positive' if x > 0 else 'Negative' for x in shap_values.values[0]]
                })
                
                # æŒ‰SHAPå€¼ç»å¯¹å€¼æ’åº
                feature_impact['Abs_SHAP'] = abs(feature_impact['SHAP Value'])
                feature_impact = feature_impact.sort_values('Abs_SHAP', ascending=False)
                
                st.dataframe(feature_impact[['Feature', 'Input Value', 'SHAP Value', 'Impact']], 
                           use_container_width=True)
                
                # æ·»åŠ è§£é‡Šæ–‡æœ¬
                st.markdown(f"**{texts['impact_explanation']}**")
                for _, row in feature_impact.iterrows():
                    impact_text = "increases" if row['SHAP Value'] > 0 else "decreases"
                    st.write(f"â€¢ **{row['Feature']}**: {impact_text} the probability of being healthy by {abs(row['SHAP Value']):.3f}")
                
            except Exception as e:
                st.error(f"AI explanation failed: {e}")
        else:
            # å¦‚æœæ²¡æœ‰SHAPï¼Œæ˜¾ç¤ºç®€å•çš„ç‰¹å¾é‡è¦æ€§
            st.subheader(f"ğŸ“Š {texts['feature_importance']}")
            if hasattr(model, 'feature_importances_'):
                feature_importance = model.feature_importances_
                features = ['Sodium', 'Protein', 'procef_4', 'Energy']
                
                fig, ax = plt.subplots(figsize=(10, 6))
                bars = ax.barh(features, feature_importance)
                ax.set_xlabel('Importance')
                ax.set_title(texts['feature_importance'])
                
                for i, bar in enumerate(bars):
                    width = bar.get_width()
                    ax.text(width, bar.get_y() + bar.get_height()/2, 
                            f'{width:.3f}', ha='left', va='center')
                
                st.pyplot(fig)
            else:
                st.warning("âš ï¸ AI explanation not available" if lang_code == "en" else "âš ï¸ AIè§£é‡Šä¸å¯ç”¨")
        
        # 7. æ·»åŠ å»ºè®®
        st.subheader(f"ğŸ’¡ {texts['recommendations']}")
        if prediction == 0:  # Unhealthy
            st.warning(f"**{texts['unhealthy_advice']}**")
            if sodium > 400:
                st.write(f"â€¢ {texts['reduce_sodium']} (current: {sodium:.0f}mg/100g)")
            if energy > 1000:
                st.write(f"â€¢ {texts['lower_energy']} (current: {energy:.0f}kJ/100g)")
            if protein < 10:
                st.write(f"â€¢ {texts['increase_protein']} (current: {protein:.1f}g/100g)")
            if procef_4 == 1:
                st.write(f"â€¢ {texts['less_processed']}")
        else:  # Healthy
            st.success(f"**{texts['healthy_advice']}**")
            st.write(texts["keep_healthy"])
            
    except Exception as e:
        st.error(f"âŒ Assessment failed: {e}" if lang_code == "en" else f"âŒ è¯„ä¼°å¤±è´¥: {e}")
        st.write("Please check your input data and try again." if lang_code == "en" else "è¯·æ£€æŸ¥æ‚¨çš„è¾“å…¥æ•°æ®å¹¶é‡è¯•ã€‚")

# ===== æ·»åŠ ä¿¡æ¯é¢æ¿ =====
st.markdown("---")
st.subheader(f"â„¹ï¸ {texts['about_title']}")

# ä½¿å‘½è¯´æ˜
st.markdown(f"""
<div class="mission-box">
    <h4>{texts['mission']}</h4>
    <p style="margin: 0; font-size: 1rem;">
        {texts['mission_text']}
    </p>
</div>
""", unsafe_allow_html=True)

col1, col2, col3 = st.columns(3)

with col1:
    st.markdown(f"""
    **ğŸ¤– {texts['model_info']}:**
    - {texts['algorithm']}: XGBoost AI
    - {texts['features']}: 4 nutritional indicators
    - {texts['training']}: Cross-validated
    - {texts['accuracy']}: High performance
    """)

with col2:
    st.markdown(f"""
    **ğŸ“Š {texts['features_used']}:**
    - {texts['sodium_content']}
    - {texts['protein_content']}
    - {texts['processing_level']}
    - {texts['energy_content']}
    """)

with col3:
    st.markdown(f"""
    **ğŸ¯ {texts['classification']}:**
    - {texts['healthy_label']}: AI prediction = 1
    - {texts['unhealthy_label']}: AI prediction = 0
    - {texts['based_on']}
    """)

# åº”ç”¨åœºæ™¯
st.markdown(f"### ğŸŒ {texts['use_cases']}")
st.markdown(f"""
- {texts['use_case_1']}
- {texts['use_case_2']}
- {texts['use_case_3']}
- {texts['use_case_4']}
""")

# ===== é¡µè„š =====
st.markdown("---")
st.markdown(f"""
<div style="text-align: center; color: #666; margin-top: 2rem;">
    <p>{texts['footer']}</p>
    <p>{texts['copyright']}</p>
</div>
""", unsafe_allow_html=True)
