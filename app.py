import streamlit as st
import numpy as np
import pandas as pd
import joblib
import matplotlib.pyplot as plt
import streamlit.components.v1 as components
import warnings
import shap

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings('ignore')

# ===== å¤šè¯­è¨€æ”¯æŒ =====
LANGUAGES = {
    "English": "en",
    "ä¸­æ–‡": "zh"
}

TEXTS = {
    "en": {
        "title": "ðŸ± Predicting Nutritional Healthiness of Ready Food",
        "subtitle": "AI-Powered Nutritional Health Assessment for Countries with Limited Nutritional Information",
        "description": "This app uses a trained XGBoost model to classify whether a ready-to-eat food is **healthy**, based on simplified input features.",
        "target_audience": "Target Audience: Countries with Missing Nutritional Information",
        "input_title": "ðŸ”¢ Input Variables",
        "sodium_label": "Sodium (mg/100g)",
        "protein_label": "Protein (g/100g)",
        "procef_4_label": "Is Ultra-Processed? (procef_4)",
        "energy_label": "Energy (kJ/100g)",
        "predict_button": "ðŸ§® Predict",
        "prediction_title": "ðŸ” Prediction Result",
        "healthy": "âœ… Healthy",
        "unhealthy": "âš ï¸ Unhealthy",
        "confidence": "Confidence (probability of being healthy)",
        "feature_importance": "ðŸ“Š Feature Importance",
        "feature_impact": "ðŸ“‹ Feature Impact Analysis",
        "recommendations": "ðŸ’¡ Recommendations",
        "unhealthy_recommendations": "This food item is classified as unhealthy. Consider:",
        "healthy_recommendations": "This food item is classified as healthy! âœ…",
        "reduce_sodium": "Reduce sodium content",
        "lower_energy": "Lower energy density",
        "increase_protein": "Increase protein content",
        "less_processed": "Consider less processed alternatives",
        "keep_good_choices": "Keep up the good nutritional choices!",
        "about_title": "â„¹ï¸ About This App",
        "model_info": "Model Information:",
        "features_used": "Features Used:",
        "classification": "Classification:",
        "algorithm": "Algorithm: XGBoost",
        "features_count": "Features: 4 nutritional indicators",
        "training": "Training: Cross-validated",
        "accuracy": "Accuracy: High performance",
        "sodium_content": "Sodium content",
        "protein_content": "Protein content",
        "processing_level": "Processing level",
        "energy_content": "Energy content",
        "healthy_class": "Healthy: Model prediction = 1",
        "unhealthy_class": "Unhealthy: Model prediction = 0",
        "based_on": "Based on nutritional features",
        "shap_explanation": "ðŸ”¬ SHAP Force Plot",
        "footer": "Developed using Streamlit and XGBoost Â· For research use only."
    },
    "zh": {
        "title": "ðŸ± å³é£Ÿé£Ÿå“è¥å…»å¥åº·åº¦é¢„æµ‹å™¨",
        "subtitle": "é¢å‘è¥å…»ç´ ä¿¡æ¯ç¼ºå¤±å›½å®¶çš„AIé©±åŠ¨è¥å…»å¥åº·è¯„ä¼°",
        "description": "æœ¬åº”ç”¨ä½¿ç”¨è®­ç»ƒå¥½çš„XGBoostæ¨¡åž‹ï¼ŒåŸºäºŽç®€åŒ–çš„è¾“å…¥ç‰¹å¾å¯¹å³é£Ÿé£Ÿå“æ˜¯å¦**å¥åº·**è¿›è¡Œåˆ†ç±»ã€‚",
        "target_audience": "ç›®æ ‡ç”¨æˆ·ï¼šè¥å…»ç´ ä¿¡æ¯ç¼ºå¤±çš„å›½å®¶",
        "input_title": "ðŸ”¢ è¾“å…¥å˜é‡",
        "sodium_label": "é’ å«é‡ (mg/100g)",
        "protein_label": "è›‹ç™½è´¨å«é‡ (g/100g)",
        "procef_4_label": "æ˜¯å¦è¶…åŠ å·¥ï¼Ÿ(procef_4)",
        "energy_label": "èƒ½é‡ (kJ/100g)",
        "predict_button": "ðŸ§® é¢„æµ‹",
        "prediction_title": "ðŸ” é¢„æµ‹ç»“æžœ",
        "healthy": "âœ… å¥åº·",
        "unhealthy": "âš ï¸ ä¸å¥åº·",
        "confidence": "ç½®ä¿¡åº¦ï¼ˆå¥åº·æ¦‚çŽ‡ï¼‰",
        "feature_importance": "ðŸ“Š ç‰¹å¾é‡è¦æ€§",
        "feature_impact": "ðŸ“‹ ç‰¹å¾å½±å“åˆ†æž",
        "recommendations": "ðŸ’¡ å»ºè®®",
        "unhealthy_recommendations": "è¯¥é£Ÿå“è¢«åˆ†ç±»ä¸ºä¸å¥åº·ã€‚å»ºè®®è€ƒè™‘ï¼š",
        "healthy_recommendations": "è¯¥é£Ÿå“è¢«åˆ†ç±»ä¸ºå¥åº·ï¼âœ…",
        "reduce_sodium": "å‡å°‘é’ å«é‡",
        "lower_energy": "é™ä½Žèƒ½é‡å¯†åº¦",
        "increase_protein": "å¢žåŠ è›‹ç™½è´¨å«é‡",
        "less_processed": "è€ƒè™‘è¾ƒå°‘åŠ å·¥çš„æ›¿ä»£å“",
        "keep_good_choices": "ç»§ç»­ä¿æŒè‰¯å¥½çš„è¥å…»é€‰æ‹©ï¼",
        "about_title": "â„¹ï¸ å…³äºŽæœ¬åº”ç”¨",
        "model_info": "æ¨¡åž‹ä¿¡æ¯ï¼š",
        "features_used": "ä½¿ç”¨çš„ç‰¹å¾ï¼š",
        "classification": "åˆ†ç±»ï¼š",
        "algorithm": "ç®—æ³•ï¼šXGBoost",
        "features_count": "ç‰¹å¾ï¼š4ä¸ªè¥å…»æŒ‡æ ‡",
        "training": "è®­ç»ƒï¼šäº¤å‰éªŒè¯",
        "accuracy": "å‡†ç¡®çŽ‡ï¼šé«˜æ€§èƒ½",
        "sodium_content": "é’ å«é‡",
        "protein_content": "è›‹ç™½è´¨å«é‡",
        "processing_level": "åŠ å·¥æ°´å¹³",
        "energy_content": "èƒ½é‡å«é‡",
        "healthy_class": "å¥åº·ï¼šæ¨¡åž‹é¢„æµ‹ = 1",
        "unhealthy_class": "ä¸å¥åº·ï¼šæ¨¡åž‹é¢„æµ‹ = 0",
        "based_on": "åŸºäºŽè¥å…»ç‰¹å¾",
        "shap_explanation": "ðŸ”¬ SHAPåŠ›å›¾",
        "footer": "ä½¿ç”¨Streamlitå’ŒXGBoostå¼€å‘ Â· ä»…ä¾›ç ”ç©¶ä½¿ç”¨ã€‚"
    }
}

# ===== é¡µé¢è®¾ç½® =====
st.set_page_config(page_title="Nutritional Quality Classifier", layout="wide")

# ä¾§è¾¹æ è¯­è¨€é€‰æ‹©
with st.sidebar:
    st.markdown("### ðŸŒ Language / è¯­è¨€")
    lang_key = st.selectbox("", list(LANGUAGES.keys()))
    lang = LANGUAGES[lang_key]

# æ ¹æ®é€‰æ‹©çš„è¯­è¨€æ˜¾ç¤ºå†…å®¹
st.title(TEXTS[lang]['title'])
st.markdown(f"**{TEXTS[lang]['subtitle']}**")
st.markdown(TEXTS[lang]['description'])

# æ˜¾ç¤ºç›®æ ‡ç”¨æˆ·ä¿¡æ¯
st.info(f"ðŸŽ¯ {TEXTS[lang]['target_audience']}")

# ===== åŠ è½½æ¨¡åž‹ã€æ ‡å‡†åŒ–å™¨å’ŒèƒŒæ™¯æ•°æ® =====
@st.cache_resource
def load_model():
    try:
        model = joblib.load("XGBoost_retrained_model.pkl")
        st.success("âœ… Model loaded successfully")
        return model
    except Exception as e:
        st.error(f"âŒ Failed to load model: {e}")
        st.error("Please ensure 'XGBoost_retrained_model.pkl' exists and is compatible")
        return None

@st.cache_resource
def load_scaler():
    try:
        scaler = joblib.load("scaler2.pkl")
        st.success("âœ… Scaler loaded successfully")
        return scaler
    except Exception as e:
        st.error(f"âŒ Failed to load scaler: {e}")
        st.error("Please ensure 'scaler2.pkl' exists and is compatible")
        return None

@st.cache_resource
def load_background_data():
    try:
        data = np.load("background_data.npy")
        st.success("âœ… Background data loaded successfully")
        return data
    except Exception as e:
        st.warning(f"âš ï¸ Failed to load background data: {e}")
        st.warning("Creating simulated background data...")
        np.random.seed(42)
        return np.random.normal(0, 1, (100, 4))

# åŠ è½½ç»„ä»¶
with st.spinner("ðŸ”„ Loading model and data..."):
    model = load_model()
    scaler = load_scaler()
    background_data = load_background_data()

if model is None or scaler is None:
    st.error("âŒ Cannot proceed without model and scaler files")
    st.stop()

# æ˜¾ç¤ºåŠ è½½çŠ¶æ€
st.info(f"ðŸ“Š Model type: {type(model).__name__}")
st.info(f"ðŸ“Š Scaler features: {len(scaler.feature_names_in_) if hasattr(scaler, 'feature_names_in_') else 'Unknown'}")
st.info(f"ðŸ“Š Background data shape: {background_data.shape}")

# ===== ä¾§è¾¹æ è¾“å…¥ =====
st.sidebar.header(TEXTS[lang]['input_title'])
sodium = st.sidebar.number_input(TEXTS[lang]['sodium_label'], min_value=0.0, step=1.0, value=400.0)
protein = st.sidebar.number_input(TEXTS[lang]['protein_label'], min_value=0.0, step=0.1, value=15.0)
procef_4 = st.sidebar.selectbox(TEXTS[lang]['procef_4_label'], [0, 1])
energy = st.sidebar.number_input(TEXTS[lang]['energy_label'], min_value=0.0, step=1.0, value=1000.0)

# ===== æ¨¡åž‹é¢„æµ‹ =====
if st.sidebar.button(TEXTS[lang]['predict_button']):
    try:
        # 1. å‡†å¤‡è¾“å…¥æ•°æ®ï¼ˆ4ä¸ªç‰¹å¾ï¼‰
        input_data = np.array([[sodium, protein, procef_4, energy]])
        
        # 2. æ ‡å‡†åŒ–
        input_scaled = scaler.transform(input_data)
        
        # 3. åˆ›å»ºDataFrame
        user_scaled_df = pd.DataFrame(input_scaled, columns=['Sodium', 'Protein', 'procef_4', 'Energy'])
        
        # 4. é¢„æµ‹
        prediction = model.predict(user_scaled_df)[0]
        prob = model.predict_proba(user_scaled_df)[0][1]
        
        # 5. å±•ç¤ºç»“æžœ
        st.subheader(TEXTS[lang]['prediction_title'])
        label = TEXTS[lang]['healthy'] if prediction == 1 else TEXTS[lang]['unhealthy']
        st.markdown(f"**Prediction:** {label}")
        st.markdown(f"**{TEXTS[lang]['confidence']}:** `{prob:.2f}`")
        
        # 6. ç‰¹å¾é‡è¦æ€§ï¼ˆå¦‚æžœæ¨¡åž‹æ”¯æŒï¼‰
        if hasattr(model, 'feature_importances_'):
            st.subheader(TEXTS[lang]['feature_importance'])
            feature_importance = model.feature_importances_
            features = ['Sodium', 'Protein', 'procef_4', 'Energy']
            
            # åˆ›å»ºé‡è¦æ€§å›¾è¡¨
            fig, ax = plt.subplots(figsize=(10, 6))
            bars = ax.barh(features, feature_importance)
            ax.set_xlabel('Importance')
            ax.set_title('Feature Importance')
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for i, bar in enumerate(bars):
                width = bar.get_width()
                ax.text(width, bar.get_y() + bar.get_height()/2, 
                        f'{width:.3f}', ha='left', va='center')
            
            st.pyplot(fig)
        
        # 7. ç‰¹å¾å½±å“åˆ†æž
        st.subheader(TEXTS[lang]['feature_impact'])
        feature_impact = pd.DataFrame({
            'Feature': ['Sodium', 'Protein', 'procef_4', 'Energy'],
            'Input Value': input_data[0],
            'Normalized Value': input_scaled[0]
        })
        
        st.dataframe(feature_impact, use_container_width=True)
        
        # 8. SHAPåŠ›å›¾
        st.subheader(TEXTS[lang]['shap_explanation'])
        
        try:
            # æ£€æŸ¥æ¨¡åž‹ç±»åž‹
            if hasattr(model, 'steps'):  # å¦‚æžœæ˜¯ Pipeline
                # èŽ·å– Pipeline ä¸­çš„æœ€ç»ˆæ¨¡åž‹
                final_model = model.named_steps[list(model.named_steps.keys())[-1]]
                input_transformed = model[:-1].transform(input_data)
                
                # ä½¿ç”¨ TreeExplainer
                explainer = shap.TreeExplainer(final_model)
                shap_values = explainer.shap_values(input_transformed)
                
                # åˆ›å»ºåŠ›å›¾
                fig, ax = plt.subplots(figsize=(12, 6))
                shap.force_plot(
                    explainer.expected_value,
                    shap_values[0],
                    input_transformed[0],
                    feature_names=['Sodium', 'Protein', 'procef_4', 'Energy'],
                    matplotlib=True,
                    show=False
                )
                st.pyplot(fig)
                plt.close()
                
            else:  # å¦‚æžœæ˜¯æ™®é€šæ¨¡åž‹
                # ä½¿ç”¨ TreeExplainer
                explainer = shap.TreeExplainer(model)
                shap_values = explainer.shap_values(input_scaled)
                
                # åˆ›å»ºåŠ›å›¾
                fig, ax = plt.subplots(figsize=(12, 6))
                shap.force_plot(
                    explainer.expected_value,
                    shap_values[0],
                    input_scaled[0],
                    feature_names=['Sodium', 'Protein', 'procef_4', 'Energy'],
                    matplotlib=True,
                    show=False
                )
                st.pyplot(fig)
                plt.close()
                
        except Exception as e:
            st.warning(f"SHAP force plot error: {str(e)}")
            st.info("ðŸ’¡ Tip: This might be due to Pipeline model structure. SHAP force plot may not be available for this model type.")
        
        # 9. æ·»åŠ å»ºè®®
        st.subheader(TEXTS[lang]['recommendations'])
        if prediction == 0:  # Unhealthy
            st.warning(f"**{TEXTS[lang]['unhealthy_recommendations']}**")
            if sodium > 400:
                st.write(f"â€¢ {TEXTS[lang]['reduce_sodium']} (current: {sodium:.0f}mg/100g)")
            if energy > 1000:
                st.write(f"â€¢ {TEXTS[lang]['lower_energy']} (current: {energy:.0f}kJ/100g)")
            if protein < 10:
                st.write(f"â€¢ {TEXTS[lang]['increase_protein']} (current: {protein:.1f}g/100g)")
            if procef_4 == 1:
                st.write(f"â€¢ {TEXTS[lang]['less_processed']}")
        else:  # Healthy
            st.success(f"**{TEXTS[lang]['healthy_recommendations']}**")
            st.write(TEXTS[lang]['keep_good_choices'])
            
    except Exception as e:
        st.error(f"âŒ Prediction failed: {e}")
        st.write("Please check your input data and try again.")

# ===== æ·»åŠ ä¿¡æ¯é¢æ¿ =====
st.markdown("---")
st.subheader(TEXTS[lang]['about_title'])

col1, col2, col3 = st.columns(3)

with col1:
    st.markdown(f"""
    **{TEXTS[lang]['model_info']}**
    - {TEXTS[lang]['algorithm']}
    - {TEXTS[lang]['features_count']}
    - {TEXTS[lang]['training']}
    - {TEXTS[lang]['accuracy']}
    """)

with col2:
    st.markdown(f"""
    **{TEXTS[lang]['features_used']}**
    - {TEXTS[lang]['sodium_content']}
    - {TEXTS[lang]['protein_content']}
    - {TEXTS[lang]['processing_level']}
    - {TEXTS[lang]['energy_content']}
    """)

with col3:
    st.markdown(f"""
    **{TEXTS[lang]['classification']}**
    - {TEXTS[lang]['healthy_class']}
    - {TEXTS[lang]['unhealthy_class']}
    - {TEXTS[lang]['based_on']}
    """)

# ===== é¡µè„š =====
st.markdown("---")
st.markdown(TEXTS[lang]['footer'])
