# import streamlit as st
# import numpy as np
# import pandas as pd
# import joblib
# import shap
# import matplotlib.pyplot as plt
# import streamlit.components.v1 as components

# # è®¾ç½®matplotlibå‚æ•°ï¼Œé¿å…é‡å 
# plt.rcParams.update({
#     'font.size': 10,
#     'axes.titlesize': 14,
#     'axes.labelsize': 12,
#     'xtick.labelsize': 10,
#     'ytick.labelsize': 10,
#     'legend.fontsize': 10,
#     'figure.titlesize': 16
# })

# # ===== å¤šè¯­è¨€æ”¯æŒ =====
# LANGUAGES = {
#     "English": "en",
#     "ä¸­æ–‡": "zh"
# }

# TEXTS = {
#     "en": {
#         "title": "ğŸ± Nutritional Quality Classifier",
#         "subtitle": "ML-Powered Ready-to-Eat Food Health Assessment",
#         "description": "This advanced machine learning application uses XGBoost to predict the nutritional healthiness of ready-to-eat foods based on key nutritional features.",
#         "target_audience": "ğŸ¯ Target Audience",
#         "audience_desc": "Designed for countries with limited nutritional information and consumers seeking quick, reliable food health assessments.",
#         "problem_statement": "ğŸ“Š Problem Statement",
#         "problem_desc": "Many countries lack comprehensive nutritional labeling systems, making it difficult to implement generalized positive labeling for food products.",
#         "solution": "ğŸ’¡ Our Solution",
#         "solution_desc": "Advanced ML model analyzes 4 key nutritional features to provide instant, accurate health predictions with detailed explanations.",
#         "mission": "ğŸš€ Mission",
#         "mission_desc": "Providing a practical approach for countries with incomplete nutritional information to implement effective food health assessment systems.",
#         "input_variables": "ğŸ”¢ Input Variables",
#         "protein_label": "Protein (g/100g)",
#         "sodium_label": "Sodium (mg/100g)",
#         "energy_label": "Energy (kJ/100g)",
#         "processed_label": "Is Ultra-Processed? (procef_4)",
#         "predict_button": "ğŸ§® Predict Healthiness",
#         "prediction_result": "ğŸ” Prediction Result",
#         "healthy": "âœ… Healthy",
#         "unhealthy": "âš ï¸ Unhealthy",
#         "confidence": "Confidence",
#         "feature_importance": "ğŸ“Š Feature Importance",
#         "shap_plot": "ğŸ“Š SHAP Force Plot",
#         "base_value": "Base value",
#         "final_prediction": "Final prediction",
#         "expand_shap": "Click to view SHAP force plot",
#         "shap_success": "âœ… SHAP force plot created (Matplotlib version)!",
#         "shap_html_success": "âœ… SHAP force plot created (HTML version - Backup)!",
#         "shap_custom_success": "âœ… SHAP force plot created (Custom version with feature names)!",
#         "shap_table": "ğŸ“Š SHAP Values Table",
#         "shap_table_info": "ğŸ’¡ SHAP values displayed as table",
#         "positive_impact": "Positive Impact (Higher Health)",
#         "negative_impact": "Negative Impact (Lower Health)",
#         "warning_input": "âš ï¸ Please enter values for at least one feature before predicting.",
#         "input_tip": "ğŸ’¡ Tip: Please enter the nutritional information of the food, and the system will predict its healthiness.",
#         "model_error": "âŒ Cannot proceed without model and scaler files",
#         "prediction_failed": "Prediction failed",
#         "shap_failed": "SHAP analysis failed",
#         "shap_unavailable": "ğŸ’¡ SHAP explanation is not available, but feature importance is shown above.",
#         "footer": "Developed using Streamlit and XGBoost Â· For research use only.",
#         "feature_names": ["Protein", "Sodium", "Energy", "procef_4"],
#         "chart_feature_names": ["Protein", "Sodium", "Energy", "procef_4"]  # å›¾è¡¨ç”¨è‹±æ–‡
#     },
#     "zh": {
#         "title": "ğŸ± è¥å…»è´¨é‡åˆ†ç±»å™¨",
#         "subtitle": "MLé©±åŠ¨çš„å³é£Ÿé£Ÿå“å¥åº·è¯„ä¼°",
#         "description": "è¿™ä¸ªå…ˆè¿›çš„æœºå™¨å­¦ä¹ åº”ç”¨ç¨‹åºä½¿ç”¨XGBoostæ ¹æ®å…³é”®è¥å…»ç‰¹å¾é¢„æµ‹å³é£Ÿé£Ÿå“çš„è¥å…»å¥åº·æ€§ã€‚",
#         "target_audience": "ğŸ¯ ç›®æ ‡ç”¨æˆ·",
#         "audience_desc": "ä¸“ä¸ºè¥å…»ä¿¡æ¯æœ‰é™çš„å›½å®¶å’Œå¯»æ±‚å¿«é€Ÿã€å¯é é£Ÿå“å¥åº·è¯„ä¼°çš„æ¶ˆè´¹è€…è®¾è®¡ã€‚",
#         "problem_statement": "ğŸ“Š é—®é¢˜é™ˆè¿°",
#         "problem_desc": "è®¸å¤šå›½å®¶ç¼ºä¹å…¨é¢çš„è¥å…»æ ‡ç­¾ç³»ç»Ÿï¼Œéš¾ä»¥å®æ–½é£Ÿå“çš„æ¦‚æ‹¬æ€§æ­£é¢æ ‡ç­¾ã€‚",
#         "solution": "ğŸ’¡ æˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆ",
#         "solution_desc": "å…ˆè¿›çš„MLæ¨¡å‹åˆ†æ4ä¸ªå…³é”®è¥å…»ç‰¹å¾ï¼Œæä¾›å³æ—¶ã€å‡†ç¡®çš„å¥åº·é¢„æµ‹å’Œè¯¦ç»†è§£é‡Šã€‚",
#         "mission": "ğŸš€ ä½¿å‘½",
#         "mission_desc": "ä¸ºè¥å…»ä¿¡æ¯çº°æ¼ä¸å…¨å¯¼è‡´æ— æ³•ä½¿ç”¨æ¦‚æ‹¬æ€§æ­£é¢æ ‡ç­¾çš„å›½å®¶æä¾›ä¸€ä¸ªä½¿ç”¨æ€è·¯ã€‚",
#         "input_variables": "ğŸ”¢ è¾“å…¥å˜é‡",
#         "protein_label": "è›‹ç™½è´¨ (g/100g)",
#         "sodium_label": "é’  (mg/100g)",
#         "energy_label": "èƒ½é‡ (kJ/100g)",
#         "processed_label": "æ˜¯å¦è¶…åŠ å·¥ï¼Ÿ(procef_4)",
#         "predict_button": "ğŸ§® é¢„æµ‹å¥åº·æ€§",
#         "prediction_result": "ğŸ” é¢„æµ‹ç»“æœ",
#         "healthy": "âœ… å¥åº·",
#         "unhealthy": "âš ï¸ ä¸å¥åº·",
#         "confidence": "ç½®ä¿¡åº¦",
#         "feature_importance": "ğŸ“Š ç‰¹å¾é‡è¦æ€§",
#         "shap_plot": "ğŸ“Š SHAPåŠ›å›¾",
#         "base_value": "åŸºå‡†å€¼",
#         "final_prediction": "æœ€ç»ˆé¢„æµ‹",
#         "expand_shap": "ç‚¹å‡»æŸ¥çœ‹SHAPåŠ›å›¾",
#         "shap_success": "âœ… SHAPåŠ›å›¾åˆ›å»ºæˆåŠŸ (Matplotlibç‰ˆæœ¬)!",
#         "shap_html_success": "âœ… SHAPåŠ›å›¾åˆ›å»ºæˆåŠŸ (HTMLç‰ˆæœ¬ - å¤‡ç”¨)!",
#         "shap_custom_success": "âœ… SHAPåŠ›å›¾åˆ›å»ºæˆåŠŸ (è‡ªå®šä¹‰ç‰ˆæœ¬ï¼ŒåŒ…å«ç‰¹å¾åç§°)!",
#         "shap_table": "ğŸ“Š SHAPå€¼è¡¨æ ¼",
#         "shap_table_info": "ğŸ’¡ SHAPå€¼ä»¥è¡¨æ ¼å½¢å¼æ˜¾ç¤º",
#         "positive_impact": "ç§¯æå½±å“ (æ›´é«˜å¥åº·æ€§)",
#         "negative_impact": "æ¶ˆæå½±å“ (æ›´ä½å¥åº·æ€§)",
#         "warning_input": "âš ï¸ è¯·åœ¨é¢„æµ‹å‰è‡³å°‘è¾“å…¥ä¸€ä¸ªç‰¹å¾çš„å€¼ã€‚",
#         "input_tip": "ğŸ’¡ æç¤º: è¯·è¾“å…¥é£Ÿå“çš„è¥å…»æˆåˆ†ä¿¡æ¯ï¼Œç³»ç»Ÿå°†é¢„æµ‹å…¶å¥åº·æ€§ã€‚",
#         "model_error": "âŒ æ²¡æœ‰æ¨¡å‹å’Œæ ‡å‡†åŒ–å™¨æ–‡ä»¶æ— æ³•ç»§ç»­",
#         "prediction_failed": "é¢„æµ‹å¤±è´¥",
#         "shap_failed": "SHAPåˆ†æå¤±è´¥",
#         "shap_unavailable": "ğŸ’¡ SHAPè§£é‡Šä¸å¯ç”¨ï¼Œä½†ä¸Šé¢æ˜¾ç¤ºäº†ç‰¹å¾é‡è¦æ€§ã€‚",
#         "footer": "ä½¿ç”¨Streamlitå’ŒXGBoostå¼€å‘ Â· ä»…ä¾›ç ”ç©¶ä½¿ç”¨ã€‚",
#         "feature_names": ["è›‹ç™½è´¨", "é’ ", "èƒ½é‡", "procef_4"],
#         "chart_feature_names": ["Protein", "Sodium", "Energy", "procef_4"]  # å›¾è¡¨ç”¨è‹±æ–‡
#     }
# }

# # ===== é¡µé¢è®¾ç½® =====
# st.set_page_config(
#     page_title="Nutritional Quality Classifier",
#     page_icon="ğŸ±",
#     layout="wide",
#     initial_sidebar_state="expanded"
# )

# # ===== è¯­è¨€é€‰æ‹©å™¨ =====
# def get_language():
#     col1, col2, col3 = st.columns([1, 1, 6])
#     with col1:
#         lang_choice = st.selectbox("ğŸŒ Language", list(LANGUAGES.keys()))
#     return TEXTS[LANGUAGES[lang_choice]]

# # è·å–å½“å‰è¯­è¨€æ–‡æœ¬
# texts = get_language()

# # ===== ä¸»æ ‡é¢˜åŒºåŸŸ =====
# st.markdown(f"""
# <div style="text-align: center; padding: 2rem 0; background: linear-gradient(90deg, #667eea 0%, #764ba2 100%); border-radius: 10px; margin-bottom: 2rem;">
#     <h1 style="color: white; margin: 0; font-size: 2.5rem;">{texts['title']}</h1>
#     <p style="color: #f0f0f0; margin: 0.5rem 0 0 0; font-size: 1.2rem;">{texts['subtitle']}</p>
# </div>
# """, unsafe_allow_html=True)

# # ===== åº”ç”¨æè¿° =====
# st.markdown(f"""
# <div style="background: #f8f9fa; padding: 1.5rem; border-radius: 10px; border-left: 4px solid #28a745; margin-bottom: 2rem;">
#     <p style="margin: 0; font-size: 1.1rem; line-height: 1.6;">{texts['description']}</p>
# </div>
# """, unsafe_allow_html=True)

# # ===== ä¿¡æ¯å¡ç‰‡ =====
# col1, col2 = st.columns(2)

# with col1:
#     st.markdown(f"""
#     <div style="background: #e3f2fd; padding: 1rem; border-radius: 8px; margin-bottom: 1rem;">
#         <h4 style="color: #1976d2; margin: 0 0 0.5rem 0;">{texts['target_audience']}</h4>
#         <p style="margin: 0; font-size: 0.9rem;">{texts['audience_desc']}</p>
#     </div>
#     """, unsafe_allow_html=True)

# with col2:
#     st.markdown(f"""
#     <div style="background: #f3e5f5; padding: 1rem; border-radius: 8px; margin-bottom: 1rem;">
#         <h4 style="color: #7b1fa2; margin: 0 0 0.5rem 0;">{texts['problem_statement']}</h4>
#         <p style="margin: 0; font-size: 0.9rem;">{texts['problem_desc']}</p>
#     </div>
#     """, unsafe_allow_html=True)

# col3, col4 = st.columns(2)

# with col3:
#     st.markdown(f"""
#     <div style="background: #e8f5e8; padding: 1rem; border-radius: 8px; margin-bottom: 1rem;">
#         <h4 style="color: #2e7d32; margin: 0 0 0.5rem 0;">{texts['solution']}</h4>
#         <p style="margin: 0; font-size: 0.9rem;">{texts['solution_desc']}</p>
#     </div>
#     """, unsafe_allow_html=True)

# with col4:
#     st.markdown(f"""
#     <div style="background: #fff3e0; padding: 1rem; border-radius: 8px; margin-bottom: 1rem;">
#         <h4 style="color: #f57c00; margin: 0 0 0.5rem 0;">{texts['mission']}</h4>
#         <p style="margin: 0; font-size: 0.9rem;">{texts['mission_desc']}</p>
#     </div>
#     """, unsafe_allow_html=True)

# # ===== åŠ è½½æ¨¡å‹ =====
# @st.cache_resource
# def load_model():
#     try:
#         return joblib.load("XGBoost_retrained_model.pkl")
#     except Exception as e:
#         st.error(f"Model loading failed: {e}")
#         return None

# @st.cache_resource
# def load_scaler():
#     try:
#         return joblib.load("scaler2.pkl")
#     except Exception as e:
#         st.error(f"Scaler loading failed: {e}")
#         return None

# model = load_model()
# scaler = load_scaler()

# if model is None or scaler is None:
#     st.error(texts['model_error'])
#     st.stop()

# # ===== ä¾§è¾¹æ è¾“å…¥ =====
# st.sidebar.markdown(f"## {texts['input_variables']}")

# # æ·»åŠ è¾“å…¥è¯´æ˜ - ä¿®å¤è¯­è¨€é—®é¢˜
# st.sidebar.markdown(f"""
# <div style="background: #f0f8ff; padding: 1rem; border-radius: 8px; margin-bottom: 1rem;">
#     <p style="margin: 0; font-size: 0.9rem; color: #1976d2;">
#         <strong>{texts['input_tip']}</strong>
#     </p>
# </div>
# """, unsafe_allow_html=True)

# protein = st.sidebar.number_input(texts['protein_label'], min_value=0.0, step=0.1, help="æ¯100gé£Ÿå“ä¸­çš„è›‹ç™½è´¨å«é‡")
# sodium = st.sidebar.number_input(texts['sodium_label'], min_value=0.0, step=1.0, help="æ¯100gé£Ÿå“ä¸­çš„é’ å«é‡")
# energy = st.sidebar.number_input(texts['energy_label'], min_value=0.0, step=1.0, help="æ¯100gé£Ÿå“ä¸­çš„èƒ½é‡å«é‡")
# procef_4 = st.sidebar.selectbox(texts['processed_label'], [0, 1], help="0=éè¶…åŠ å·¥, 1=è¶…åŠ å·¥")

# # æ·»åŠ é¢„æµ‹æŒ‰é’®æ ·å¼
# if st.sidebar.button(texts['predict_button'], type="primary", use_container_width=True):
#     # æ£€æŸ¥è¾“å…¥æ˜¯å¦ä¸ºé›¶
#     if protein == 0 and sodium == 0 and energy == 0:
#         st.warning(texts['warning_input'])
#         st.stop()
    
#     try:
#         # 1. å‡†å¤‡è¾“å…¥æ•°æ®
#         input_data = np.array([[protein, sodium, energy, procef_4]], dtype=float)
#         input_scaled = scaler.transform(input_data)
#         user_scaled_df = pd.DataFrame(input_scaled, columns=texts['chart_feature_names'])  # ä½¿ç”¨è‹±æ–‡ç‰¹å¾åç”¨äºæ•°æ®å¤„ç†
        
#         # 2. é¢„æµ‹
#         prediction = model.predict(user_scaled_df)[0]
#         prob = model.predict_proba(user_scaled_df)[0][1]
        
#         # 3. å±•ç¤ºç»“æœ - ç¾åŒ–
#         st.markdown(f"## {texts['prediction_result']}")
        
#         # ç»“æœå¡ç‰‡
#         if prediction == 1:
#             result_color = "#28a745"
#             result_icon = "âœ…"
#             result_text = texts['healthy']
#         else:
#             result_color = "#dc3545"
#             result_icon = "âš ï¸"
#             result_text = texts['unhealthy']
        
#         st.markdown(f"""
#         <div style="background: {result_color}; color: white; padding: 2rem; border-radius: 10px; text-align: center; margin: 1rem 0;">
#             <h2 style="margin: 0; font-size: 2rem;">{result_icon} {result_text}</h2>
#             <p style="margin: 0.5rem 0 0 0; font-size: 1.2rem;">{texts['confidence']}: <strong>{prob:.2f}</strong></p>
#         </div>
#         """, unsafe_allow_html=True)
        
#         # 4. ç‰¹å¾é‡è¦æ€§
#         st.markdown(f"## {texts['feature_importance']}")
        
#         if hasattr(model, 'steps'):
#             final_model = model.steps[-1][1]
#             if hasattr(final_model, 'feature_importances_'):
#                 feature_importance = final_model.feature_importances_
#                 features = texts['chart_feature_names']  # ä½¿ç”¨è‹±æ–‡ç‰¹å¾åç”¨äºå›¾è¡¨
                
#                 fig, ax = plt.subplots(figsize=(10, 6))
#                 bars = ax.barh(features, feature_importance, color=['#ff6b6b', '#4ecdc4', '#45b7d1', '#96ceb4'])
#                 ax.set_xlabel('Importance', fontsize=12)
#                 ax.set_title('Feature Importance Analysis', fontsize=14, fontweight='bold')
                
#                 for i, bar in enumerate(bars):
#                     width = bar.get_width()
#                     ax.text(width, bar.get_y() + bar.get_height()/2, 
#                             f'{width:.3f}', ha='left', va='center', fontweight='bold')
                
#                 plt.tight_layout()
#                 st.pyplot(fig)
#                 plt.close()
        
#         # 5. SHAPåŠ›å›¾
#         st.markdown(f"## {texts['shap_plot']}")
        
#         try:
#             # åˆ›å»ºèƒŒæ™¯æ•°æ®
#             np.random.seed(42)
#             background_data = np.random.normal(0, 1, (100, 4)).astype(float)
            
#             # ä½¿ç”¨ Explainer
#             explainer = shap.Explainer(model.predict_proba, background_data)
#             shap_values = explainer(user_scaled_df)
            
#             # è®¡ç®—æœŸæœ›å€¼
#             background_predictions = model.predict_proba(background_data)
#             expected_value = background_predictions.mean(axis=0)
            
#             # è·å– SHAP å€¼
#             if hasattr(shap_values, 'values'):
#                 if len(shap_values.values.shape) == 3:
#                     shap_vals = shap_values.values[0, :, 1]  # å¥åº·ç±»åˆ«
#                     base_val = expected_value[1]
#                 else:
#                     shap_vals = shap_values.values[0, :]
#                     base_val = expected_value[0]
#             else:
#                 shap_vals = shap_values[0, :]
#                 base_val = expected_value[0]
            
#             # æ˜¾ç¤º SHAP å€¼ä¿¡æ¯
#             col1, col2 = st.columns(2)
#             with col1:
#                 st.metric(texts['base_value'], f"{base_val:.4f}")
#             with col2:
#                 st.metric(texts['final_prediction'], f"{base_val + shap_vals.sum():.4f}")
            
#             # åˆ›å»º SHAP åŠ›å›¾
#             with st.expander(texts['expand_shap'], expanded=True):
#                 # æ–¹æ³•1ï¼šä¼˜å…ˆä½¿ç”¨matplotlibç‰ˆæœ¬
#                 try:
#                     # è®¾ç½®æ›´å¤§çš„å›¾å½¢å°ºå¯¸ï¼Œé¿å…é‡å 
#                     plt.figure(figsize=(20, 8))  # å¢åŠ é«˜åº¦
                    
#                     # åˆ›å»ºSHAPåŠ›å›¾ï¼Œç¡®ä¿åŒ…å«ç‰¹å¾åç§°
#                     shap.force_plot(base_val, shap_vals,
#                                    user_scaled_df.iloc[0], 
#                                    feature_names=texts['chart_feature_names'],  # ä½¿ç”¨è‹±æ–‡ç‰¹å¾åç§°
#                                    matplotlib=True, show=False)
                    
#                     plt.title('SHAP Force Plot - Current Prediction', fontsize=16, fontweight='bold', pad=30)
#                     plt.tight_layout()
#                     st.pyplot(plt)
#                     plt.close()
#                     st.success(texts['shap_success'])
                    
#                 except Exception as e:
#                     st.warning(f"Matplotlib version failed: {e}")
                    
#                     # æ–¹æ³•2ï¼šä½¿ç”¨ HTML ç‰ˆæœ¬ä½œä¸ºå¤‡ç”¨
#                     try:
#                         force_plot = shap.force_plot(
#                             base_val,
#                             shap_vals,
#                             user_scaled_df.iloc[0],
#                             feature_names=texts['chart_feature_names'],  # ä½¿ç”¨è‹±æ–‡ç‰¹å¾åç§°
#                             matplotlib=False
#                         )
                        
#                         # è½¬æ¢ä¸º HTML
#                         force_html = force_plot.html()
#                         components.html(shap.getjs() + force_html, height=400)
#                         st.success(texts['shap_html_success'])
                        
#                     except Exception as e2:
#                         st.warning(f"HTML version also failed: {e2}")
                        
#                         # æ–¹æ³•3ï¼šè‡ªå®šä¹‰æ¸…æ™°çš„æ¡å½¢å›¾ï¼ˆå¸¦ç‰¹å¾åç§°ï¼‰
#                         try:
#                             fig, ax = plt.subplots(figsize=(15, 8))
                            
#                             features = texts['chart_feature_names']  # ä½¿ç”¨è‹±æ–‡ç‰¹å¾åç§°
#                             feature_values = user_scaled_df.iloc[0].values
                            
#                             # åˆ›å»ºæ¡å½¢å›¾
#                             colors = ['#ff6b6b' if x < 0 else '#4ecdc4' for x in shap_vals]
#                             bars = ax.barh(features, shap_vals, color=colors, alpha=0.8, height=0.6)
                            
#                             # æ·»åŠ ç‰¹å¾åç§°å’Œæ•°å€¼æ ‡ç­¾
#                             for i, (bar, shap_val, feature_val, feature_name) in enumerate(zip(bars, shap_vals, feature_values, features)):
#                                 width = bar.get_width()
#                                 y_pos = bar.get_y() + bar.get_height()/2
                                
#                                 # åœ¨æ¡å½¢å›¾å†…éƒ¨æ˜¾ç¤ºSHAPå€¼
#                                 ax.text(width/2, y_pos, f'{shap_val:.3f}', 
#                                        ha='center', va='center', color='white', fontweight='bold', fontsize=12)
                                
#                                 # åœ¨æ¡å½¢å›¾å¤–éƒ¨æ˜¾ç¤ºç‰¹å¾åç§°å’Œå€¼
#                                 if width > 0:
#                                     ax.text(width + 0.05, y_pos, f'{feature_name}: {feature_val:.2f}', 
#                                            ha='left', va='center', fontsize=11, fontweight='bold',
#                                            bbox=dict(boxstyle="round,pad=0.4", facecolor="lightblue", alpha=0.8))
#                                 else:
#                                     ax.text(width - 0.05, y_pos, f'{feature_name}: {feature_val:.2f}', 
#                                            ha='right', va='center', fontsize=11, fontweight='bold',
#                                            bbox=dict(boxstyle="round,pad=0.4", facecolor="lightcoral", alpha=0.8))
                            
#                             # æ·»åŠ é›¶çº¿
#                             ax.axvline(x=0, color='black', linestyle='-', alpha=0.5, linewidth=2)
#                             ax.set_xlabel('SHAP Value', fontsize=12)
#                             ax.set_ylabel('Features', fontsize=12)
#                             ax.set_title('SHAP Force Plot - Feature Contributions', fontsize=14, pad=20)
#                             ax.grid(True, alpha=0.3)
                            
#                             # æ·»åŠ å›¾ä¾‹
#                             legend_elements = [
#                                 plt.Rectangle((0,0),1,1, facecolor='#4ecdc4', alpha=0.8, label=texts['positive_impact']),
#                                 plt.Rectangle((0,0),1,1, facecolor='#ff6b6b', alpha=0.8, label=texts['negative_impact'])
#                             ]
#                             ax.legend(handles=legend_elements, loc='upper right', fontsize=10)
                            
#                             plt.tight_layout()
#                             st.pyplot(fig)
#                             plt.close()
#                             st.success(texts['shap_custom_success'])
                            
#                         except Exception as e3:
#                             st.error(f"All SHAP plots failed: {e3}")
                            
#                             # æ–¹æ³•4ï¼šæ˜¾ç¤ºè¯¦ç»†è¡¨æ ¼
#                             st.markdown(f"### {texts['shap_table']}")
#                             shap_df = pd.DataFrame({
#                                 'Feature': features,
#                                 'Feature Value': feature_values,
#                                 'SHAP Value': shap_vals,
#                                 'Impact': [texts['negative_impact'] if x < 0 else texts['positive_impact'] for x in shap_vals]
#                             })
#                             st.dataframe(shap_df, use_container_width=True)
#                             st.info(texts['shap_table_info'])
            
#         except Exception as e:
#             st.error(f"{texts['shap_failed']}: {e}")
#             st.info(texts['shap_unavailable'])
            
#     except Exception as e:
#         st.error(f"{texts['prediction_failed']}: {e}")

# # ===== é¡µè„š =====
# st.markdown("---")
# st.markdown(f"""
# <div style="text-align: center; padding: 2rem 0; color: #666;">
#     <p style="margin: 0;">{texts['footer']}</p>
# </div>
# """, unsafe_allow_html=True)


import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import warnings
import os
import sys

# ä¾èµ–æ£€æŸ¥
def check_dependencies():
    missing_deps = []
    try:
        import joblib
    except ImportError:
        missing_deps.append("joblib")
    
    try:
        import shap
    except ImportError:
        missing_deps.append("shap")
    
    try:
        from imblearn.pipeline import Pipeline
    except ImportError:
        try:
            from sklearn.pipeline import Pipeline
        except ImportError:
            missing_deps.append("scikit-learn")
    
    if missing_deps:
        st.error(f"âŒ Missing dependencies: {', '.join(missing_deps)}")
        st.info("Please install with: pip install " + " ".join(missing_deps))
        st.stop()
    
    return True

# æ£€æŸ¥ä¾èµ–
check_dependencies()

# å¯¼å…¥å…¶ä»–åº“
import joblib
import shap
import streamlit.components.v1 as components

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings('ignore')

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="Nutritional Quality Classifier",
    layout="wide",
    initial_sidebar_state="expanded"
)

# å¤šè¯­è¨€æ”¯æŒ
LANGUAGES = {
    "English": "en",
    "ä¸­æ–‡": "zh"
}

TEXTS = {
    "en": {
        "title": "ğŸ± Nutritional Quality Classifier",
        "subtitle": "ML-powered food health assessment for countries with limited nutritional information",
        "mission": "Mission",
        "mission_desc": "Providing a practical approach for countries with incomplete nutritional information to implement effective food health assessment systems.",
        "problem": "Problem Statement",
        "problem_desc": "Many countries lack comprehensive nutritional labeling, making it difficult for consumers to make informed food choices. This tool bridges that gap using machine learning.",
        "input_vars": "Input Variables",
        "sodium": "Sodium (mg/100g)",
        "protein": "Protein (g/100g)",
        "procef": "Is Ultra-Processed?",
        "energy": "Energy (kJ/100g)",
        "predict": "Predict",
        "healthy": "HEALTHY",
        "unhealthy": "UNHEALTHY",
        "healthy_prob": "Healthy Probability",
        "unhealthy_prob": "Unhealthy Probability",
        "shap_plot": "SHAP Force Plot",
        "expand_shap": "Click to view SHAP force plot",
        "shap_success": "âœ… SHAP force plot generated successfully",
        "shap_failed": "âŒ SHAP explanation failed",
        "shap_unavailable": "ğŸ’¡ SHAP explanation is not available for this model type.",
        "prediction_failed": "âŒ Prediction failed",
        "chart_feature_names": ["Sodium", "Protein", "Ultra-Processed", "Energy"],
        "positive_impact": "Positive Impact",
        "negative_impact": "Negative Impact",
        "shap_table": "SHAP Values Table",
        "shap_table_info": "This table shows how each feature contributes to the prediction.",
        "base_value": "Base Value",
        "final_prediction": "Final Prediction"
    },
    "zh": {
        "title": "ğŸ± è¥å…»è´¨é‡åˆ†ç±»å™¨",
        "subtitle": "åŸºäºæœºå™¨å­¦ä¹ çš„é£Ÿå“å¥åº·è¯„ä¼°å·¥å…·ï¼Œä¸“ä¸ºè¥å…»ä¿¡æ¯ä¸å®Œæ•´çš„å›½å®¶è®¾è®¡",
        "mission": "ä½¿å‘½",
        "mission_desc": "ä¸ºè¥å…»ä¿¡æ¯ä¸å®Œæ•´çš„å›½å®¶æä¾›å®ç”¨çš„é£Ÿå“å¥åº·è¯„ä¼°ç³»ç»Ÿè§£å†³æ–¹æ¡ˆã€‚",
        "problem": "é—®é¢˜é™ˆè¿°",
        "problem_desc": "è®¸å¤šå›½å®¶ç¼ºä¹å…¨é¢çš„è¥å…»æ ‡ç­¾ï¼Œæ¶ˆè´¹è€…éš¾ä»¥åšå‡ºæ˜æ™ºçš„é£Ÿå“é€‰æ‹©ã€‚æœ¬å·¥å…·ä½¿ç”¨æœºå™¨å­¦ä¹ å¡«è¡¥è¿™ä¸€ç©ºç™½ã€‚",
        "input_vars": "è¾“å…¥å˜é‡",
        "sodium": "é’ å«é‡ (mg/100g)",
        "protein": "è›‹ç™½è´¨å«é‡ (g/100g)",
        "procef": "æ˜¯å¦è¶…åŠ å·¥ï¼Ÿ",
        "energy": "èƒ½é‡ (kJ/100g)",
        "predict": "é¢„æµ‹",
        "healthy": "å¥åº·",
        "unhealthy": "ä¸å¥åº·",
        "healthy_prob": "å¥åº·æ¦‚ç‡",
        "unhealthy_prob": "ä¸å¥åº·æ¦‚ç‡",
        "shap_plot": "SHAPåŠ›å›¾",
        "expand_shap": "ç‚¹å‡»æŸ¥çœ‹SHAPåŠ›å›¾",
        "shap_success": "âœ… SHAPåŠ›å›¾ç”ŸæˆæˆåŠŸ",
        "shap_failed": "âŒ SHAPè§£é‡Šå¤±è´¥",
        "shap_unavailable": "ğŸ’¡ æ­¤æ¨¡å‹ç±»å‹ä¸æ”¯æŒSHAPè§£é‡Šã€‚",
        "prediction_failed": "âŒ é¢„æµ‹å¤±è´¥",
        "chart_feature_names": ["Sodium", "Protein", "Ultra-Processed", "Energy"],
        "positive_impact": "æ­£å‘å½±å“",
        "negative_impact": "è´Ÿå‘å½±å“",
        "shap_table": "SHAPå€¼è¡¨æ ¼",
        "shap_table_info": "æ­¤è¡¨æ ¼æ˜¾ç¤ºæ¯ä¸ªç‰¹å¾å¯¹é¢„æµ‹çš„è´¡çŒ®ã€‚",
        "base_value": "åŸºå‡†å€¼",
        "final_prediction": "æœ€ç»ˆé¢„æµ‹"
    }
}

def get_language():
    return st.sidebar.selectbox("Language / è¯­è¨€", list(LANGUAGES.keys()))

# è·å–å½“å‰è¯­è¨€
current_lang = get_language()
texts = TEXTS[LANGUAGES[current_lang]]

# è‡ªå®šä¹‰CSS
st.markdown("""
<style>
.main-header {
    font-size: 2.5rem;
    font-weight: bold;
    background: linear-gradient(90deg, #2E8B57, #32CD32);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    text-align: center;
    margin-bottom: 1rem;
}

.subtitle {
    font-size: 1.2rem;
    color: #666;
    text-align: center;
    margin-bottom: 2rem;
}

.prediction-healthy {
    background: linear-gradient(135deg, #d4edda, #c3e6cb);
    color: #155724;
    padding: 1.5rem;
    border-radius: 1rem;
    border: 2px solid #c3e6cb;
    box-shadow: 0 4px 6px rgba(0,0,0,0.1);
}

.prediction-unhealthy {
    background: linear-gradient(135deg, #f8d7da, #f5c6cb);
    color: #721c24;
    padding: 1.5rem;
    border-radius: 1rem;
    border: 2px solid #f5c6cb;
    box-shadow: 0 4px 6px rgba(0,0,0,0.1);
}

.metric-card {
    background: linear-gradient(135deg, #f8f9fa, #e9ecef);
    padding: 1rem;
    border-radius: 0.5rem;
    border: 1px solid #dee2e6;
    text-align: center;
}

.sidebar .stSelectbox > div > div {
    background-color: #f8f9fa;
}
</style>
""", unsafe_allow_html=True)

# æ ‡é¢˜
st.markdown(f'<h1 class="main-header">{texts["title"]}</h1>', unsafe_allow_html=True)
st.markdown(f'<p class="subtitle">{texts["subtitle"]}</p>', unsafe_allow_html=True)

# ä½¿å‘½å’Œé—®é¢˜
col1, col2 = st.columns(2)
with col1:
    st.markdown(f"### {texts['mission']}")
    st.info(texts['mission_desc'])
with col2:
    st.markdown(f"### {texts['problem']}")
    st.info(texts['problem_desc'])

# æ¨¡å‹åŠ è½½å‡½æ•°
@st.cache_resource
def load_model():
    """åŠ è½½æ¨¡å‹ï¼Œæ”¯æŒå¤šç§è·¯å¾„å’Œæ ¼å¼"""
    possible_paths = [
        "results_20251015_112741/models/final_model.pkl",
        "final_model.pkl",
        "XGBoost_retrained_model.pkl"
    ]
    
    for path in possible_paths:
        if os.path.exists(path):
            try:
                model = joblib.load(path)
                st.success(f"âœ… Model loaded from {path}")
                return model
            except Exception as e:
                st.warning(f"âš ï¸ Failed to load {path}: {e}")
                continue
    
    st.error("âŒ No valid model file found")
    return None

@st.cache_resource
def load_scaler():
    """åŠ è½½æ ‡å‡†åŒ–å™¨"""
    possible_paths = [
        "results_20251015_112741/models/scaler.pkl",
        "scaler.pkl",
        "scaler2.pkl"
    ]
    
    for path in possible_paths:
        if os.path.exists(path):
            try:
                scaler = joblib.load(path)
                st.success(f"âœ… Scaler loaded from {path}")
                return scaler
            except Exception as e:
                st.warning(f"âš ï¸ Failed to load {path}: {e}")
                continue
    
    st.error("âŒ No valid scaler file found")
    return None

@st.cache_resource
def create_background_data():
    """åˆ›å»ºèƒŒæ™¯æ•°æ®ç”¨äºSHAPè§£é‡Š"""
    np.random.seed(42)
    return np.random.normal(0, 1, (100, 4)).astype(float)

# åŠ è½½ç»„ä»¶
with st.spinner("ğŸ”„ Loading model and data..."):
    model = load_model()
    scaler = load_scaler()
    background_data = create_background_data()

if model is None or scaler is None:
    st.error("âŒ Cannot proceed without model and scaler files")
    st.stop()

# ä¾§è¾¹æ è¾“å…¥
st.sidebar.header(f"ğŸ”¢ {texts['input_vars']}")

# 4ä¸ªç‰¹å¾è¾“å…¥
sodium = st.sidebar.number_input(
    texts['sodium'],
    min_value=0.0,
    max_value=5000.0,
    step=1.0,
    help="Sodium content per 100g of food"
)

protein = st.sidebar.number_input(
    texts['protein'],
    min_value=0.0,
    max_value=100.0,
    step=0.1,
    help="Protein content per 100g of food"
)

procef_4 = st.sidebar.selectbox(
    texts['procef'],
    [0, 1],
    format_func=lambda x: "No (0)" if x == 0 else "Yes (1)",
    help="Whether the food is ultra-processed"
)

energy = st.sidebar.number_input(
    texts['energy'],
    min_value=0.0,
    max_value=5000.0,
    step=1.0,
    help="Energy content per 100g of food"
)

# ç¤ºä¾‹æ•°æ®æŒ‰é’®
st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ“ Example Data")
col1, col2 = st.sidebar.columns(2)
with col1:
    if st.button("ğŸ Healthy Example"):
        st.session_state.sodium = 200.0
        st.session_state.protein = 20.0
        st.session_state.procef_4 = 0
        st.session_state.energy = 800.0
with col2:
    if st.button("ğŸŸ Unhealthy Example"):
        st.session_state.sodium = 800.0
        st.session_state.protein = 5.0
        st.session_state.procef_4 = 1
        st.session_state.energy = 1500.0

# é¢„æµ‹æŒ‰é’®
if st.sidebar.button(f"ğŸ§® {texts['predict']}", type="primary", use_container_width=True):
    with st.spinner("ğŸ”„ Analyzing nutritional data..."):
        try:
            # å‡†å¤‡è¾“å…¥æ•°æ®
            features = ['Sodium', 'Protein', 'procef_4', 'Energy']
            input_data = np.array([[sodium, protein, procef_4, energy]])
            
            # æ ‡å‡†åŒ–
            input_scaled = scaler.transform(input_data)
            user_scaled_df = pd.DataFrame(input_scaled, columns=features)
            
            # é¢„æµ‹
            prediction = model.predict(user_scaled_df)[0]
            probabilities = model.predict_proba(user_scaled_df)[0]
            
            # å±•ç¤ºç»“æœ
            st.subheader("ğŸ” Prediction Result")
            
            col1, col2, col3 = st.columns(3)
            with col1:
                if prediction == 1:
                    st.markdown('<div class="prediction-healthy">', unsafe_allow_html=True)
                    st.markdown(f"### âœ… **{texts['healthy']}**")
                    st.markdown("This food item is classified as healthy!")
                    st.markdown('</div>', unsafe_allow_html=True)
                else:
                    st.markdown('<div class="prediction-unhealthy">', unsafe_allow_html=True)
                    st.markdown(f"### âš ï¸ **{texts['unhealthy']}**")
                    st.markdown("This food item is classified as unhealthy.")
                    st.markdown('</div>', unsafe_allow_html=True)
            
            with col2:
                st.metric(
                    texts['healthy_prob'],
                    f"{probabilities[1]:.1%}",
                    delta=f"{(probabilities[1]-0.5)*100:+.1f}%"
                )
            
            with col3:
                st.metric(
                    texts['unhealthy_prob'],
                    f"{probabilities[0]:.1%}",
                    delta=f"{(probabilities[0]-0.5)*100:+.1f}%"
                )
            
            # SHAPåŠ›å›¾
            st.markdown(f"## {texts['shap_plot']}")
            
            try:
                # åˆ›å»ºSHAPè§£é‡Šå™¨
                explainer = shap.Explainer(model.predict_proba, background_data)
                shap_values = explainer(user_scaled_df)
                
                # è®¡ç®—æœŸæœ›å€¼
                background_predictions = model.predict_proba(background_data)
                expected_value = background_predictions.mean(axis=0)
                
                # è·å–SHAPå€¼
                if hasattr(shap_values, 'values'):
                    if len(shap_values.values.shape) == 3:
                        shap_vals = shap_values.values[0, :, 1]
                        base_val = expected_value[1]
                    else:
                        shap_vals = shap_values.values[0, :]
                        base_val = expected_value[0]
                else:
                    shap_vals = shap_values[0, :]
                    base_val = expected_value[0]
                
                # æ˜¾ç¤ºSHAPå€¼ä¿¡æ¯
                col1, col2 = st.columns(2)
                with col1:
                    st.metric(texts['base_value'], f"{base_val:.4f}")
                with col2:
                    st.metric(texts['final_prediction'], f"{base_val + shap_vals.sum():.4f}")
                
                # åˆ›å»ºSHAPåŠ›å›¾
                with st.expander(texts['expand_shap'], expanded=True):
                    try:
                        # æ–¹æ³•1ï¼šHTMLç‰ˆæœ¬ï¼ˆæ¨èï¼‰
                        force_plot = shap.force_plot(
                            base_val,
                            shap_vals,
                            user_scaled_df.iloc[0],
                            feature_names=texts['chart_feature_names'],
                            matplotlib=False
                        )
                        
                        force_html = force_plot.html()
                        components.html(shap.getjs() + force_html, height=400)
                        st.success(texts['shap_success'])
                        
                    except Exception as e:
                        st.warning(f"HTML version failed: {e}")
                        
                        # æ–¹æ³•2ï¼šè‡ªå®šä¹‰æ¡å½¢å›¾
                        try:
                            fig, ax = plt.subplots(figsize=(12, 6))
                            
                            features = texts['chart_feature_names']
                            feature_values = user_scaled_df.iloc[0].values
                            
                            colors = ['#ff6b6b' if x < 0 else '#4ecdc4' for x in shap_vals]
                            bars = ax.barh(features, shap_vals, color=colors, alpha=0.8, height=0.6)
                            
                            for i, (bar, shap_val, feature_val, feature_name) in enumerate(zip(bars, shap_vals, feature_values, features)):
                                width = bar.get_width()
                                y_pos = bar.get_y() + bar.get_height()/2
                                
                                ax.text(width/2, y_pos, f'{shap_val:.3f}', 
                                       ha='center', va='center', color='white', fontweight='bold', fontsize=10)
                                
                                if width > 0:
                                    ax.text(width + 0.05, y_pos, f'{feature_name}: {feature_val:.2f}', 
                                           ha='left', va='center', fontsize=9, fontweight='bold')
                                else:
                                    ax.text(width - 0.05, y_pos, f'{feature_name}: {feature_val:.2f}', 
                                           ha='right', va='center', fontsize=9, fontweight='bold')
                            
                            ax.axvline(x=0, color='black', linestyle='-', alpha=0.5, linewidth=2)
                            ax.set_xlabel('SHAP Value', fontsize=12)
                            ax.set_ylabel('Features', fontsize=12)
                            ax.set_title('SHAP Force Plot - Feature Contributions', fontsize=14, pad=20)
                            ax.grid(True, alpha=0.3)
                            
                            plt.tight_layout()
                            st.pyplot(fig)
                            plt.close()
                            st.success(texts['shap_success'])
                            
                        except Exception as e2:
                            st.error(f"All SHAP plots failed: {e2}")
                            
                            # æ–¹æ³•3ï¼šæ˜¾ç¤ºè¡¨æ ¼
                            st.markdown(f"### {texts['shap_table']}")
                            shap_df = pd.DataFrame({
                                'Feature': features,
                                'Feature Value': feature_values,
                                'SHAP Value': shap_vals,
                                'Impact': [texts['negative_impact'] if x < 0 else texts['positive_impact'] for x in shap_vals]
                            })
                            st.dataframe(shap_df, use_container_width=True)
                            st.info(texts['shap_table_info'])
            
            except Exception as e:
                st.error(f"{texts['shap_failed']}: {e}")
                st.info(texts['shap_unavailable'])
        
        except Exception as e:
            st.error(f"{texts['prediction_failed']}: {e}")
